{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4 Image Classifier Using Tensorflow.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"AiKhY4dYzmYl","colab_type":"text"},"cell_type":"markdown","source":["# Prepare Dataset\n"]},{"metadata":{"id":"u30_H_9fbseT","colab_type":"code","outputId":"f6a5d165-9e19-42c8-c66d-7de768547cb4","executionInfo":{"status":"ok","timestamp":1554269195398,"user_tz":-330,"elapsed":6420,"user":{"displayName":"Akash Jadhav","photoUrl":"https://lh5.googleusercontent.com/-yXv9Ny7rXxE/AAAAAAAAAAI/AAAAAAAAAAc/zGjp0Qa7nWU/s64/photo.jpg","userId":"00643688276017227396"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["ls"],"execution_count":2,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"],"name":"stdout"}]},{"metadata":{"id":"h0aAHkustZqw","colab_type":"code","outputId":"7e7925f3-3acc-4fbc-d571-43e80665f260","executionInfo":{"status":"ok","timestamp":1554269200918,"user_tz":-330,"elapsed":11896,"user":{"displayName":"Akash Jadhav","photoUrl":"https://lh5.googleusercontent.com/-yXv9Ny7rXxE/AAAAAAAAAAI/AAAAAAAAAAc/zGjp0Qa7nWU/s64/photo.jpg","userId":"00643688276017227396"}},"colab":{"base_uri":"https://localhost:8080/","height":224}},"cell_type":"code","source":["!pip install kaggle"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.3)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.3.9)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (3.0.1)\n","Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n","Requirement already satisfied: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.2)\n"],"name":"stdout"}]},{"metadata":{"id":"zFxhZxVLuAof","colab_type":"code","colab":{}},"cell_type":"code","source":["from googleapiclient.discovery import build\n","import io, os\n","from googleapiclient.http import MediaIoBaseDownload\n","from google.colab import auth\n","\n","auth.authenticate_user()\n","\n","drive_service = build('drive', 'v3')\n","results = drive_service.files().list(q=\"name = 'kaggle.json'\", fields=\"files(id)\").execute()\n","kaggle_api_key = results.get('files', [])\n","\n","filename = \"/content/.kaggle/kaggle.json\"\n","os.makedirs(os.path.dirname(filename), exist_ok=True)\n","\n","request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])\n","fh = io.FileIO(filename, 'wb')\n","downloader = MediaIoBaseDownload(fh, request)\n","done = False\n","while done is False:\n","    status, done = downloader.next_chunk()\n","    print(\"Download %d%%.\" % int(status.progress() * 100))\n","os.chmod(filename, 600)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"R1AzgoOXvEfE","colab_type":"code","colab":{}},"cell_type":"code","source":["!cat .kaggle/kaggle.json"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ybBeBrWjJbfd","colab_type":"code","colab":{}},"cell_type":"code","source":["pwd"],"execution_count":0,"outputs":[]},{"metadata":{"id":"W2fYBmVvJO-f","colab_type":"code","colab":{}},"cell_type":"code","source":["ls --all"],"execution_count":0,"outputs":[]},{"metadata":{"id":"m82762W0vmgn","colab_type":"code","colab":{}},"cell_type":"code","source":["!mkdir ~/.kaggle"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mzPEi1P7KHZ_","colab_type":"code","colab":{}},"cell_type":"code","source":["!cp .kaggle/kaggle.json ~/.kaggle/kaggle.json"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UjEylT6uwfh8","colab_type":"code","colab":{}},"cell_type":"code","source":["!mkdir dataset_cat_dog"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Z9zay9ZMwoma","colab_type":"code","colab":{}},"cell_type":"code","source":["cd dataset_cat_dog"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8Fv406yQuj7e","colab_type":"code","colab":{}},"cell_type":"code","source":["!kaggle competitions download -c dogs-vs-cats"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ggCvgcL2v964","colab_type":"code","colab":{}},"cell_type":"code","source":["ls"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xAjw3zbwwVrf","colab_type":"code","colab":{}},"cell_type":"code","source":["!unzip train.zip "],"execution_count":0,"outputs":[]},{"metadata":{"id":"egXHd7FDw5CK","colab_type":"code","colab":{}},"cell_type":"code","source":["!unzip test1.zip  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"qddQIXjtw_AH","colab_type":"code","colab":{}},"cell_type":"code","source":["rm test1.zip  train.zip"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ye3rSVUAzRoC","colab_type":"code","colab":{}},"cell_type":"code","source":["ls train/ -U | head -4"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tiZTCjOLzNnO","colab_type":"text"},"cell_type":"markdown","source":["## Saparateing The Data\n","\n","The data we get from the Kaggle dataset it’s a mixed data. means all the images of dogs and cats are in the same folder. Now let’s separate them into two separate folders.\n","\n"]},{"metadata":{"id":"Yr9oxM_TzFuI","colab_type":"code","colab":{}},"cell_type":"code","source":["import shutil\n","from os import listdir, path\n","\n","def seperateData(data_dir):\n","    for filename in listdir(data_dir):\n","        if path.isfile(path.join(data_dir, filename)):\n","            tokens = filename.split('.')\n","            if tokens[-1] == 'jpg':\n","                image_path = path.join(data_dir, filename)\n","                if not os.path.exists(path.join(data_dir, tokens[0])):\n","                    os.makedirs(path.join(data_dir, tokens[0]))\n","                shutil.copyfile(image_path, path.join(path.join(data_dir, tokens[0]), filename))\n","                os.remove(image_path)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eONt95bailEJ","colab_type":"code","colab":{}},"cell_type":"code","source":["seperateData(\"./train\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iDSS1yeqj_3i","colab_type":"code","colab":{}},"cell_type":"code","source":["!ls ./train/"],"execution_count":0,"outputs":[]},{"metadata":{"id":"p6OzKzvjxkAD","colab_type":"text"},"cell_type":"markdown","source":["So by reading the filename, we can get if it’s a dog or cat.\n","\n","Now we can read all the images and store them in a python list. and feed it to the network one by one. loading the entire dataset into your program, it will occupy too much ram probably in GB, and we don’t even need all the images at the same time. \n","\n","So we will create a Class which will get few of those images in batch, let’s say 20 images and then after we train our network on.\n","\n","\n","\n","Then the generator we collect next set of images from the folder and create another mini batch. this will continue until we are finished with all the images in the folder\n","\n"]},{"metadata":{"id":"QIxMgpPPy210","colab_type":"text"},"cell_type":"markdown","source":["## Let’s Create a Dataset Generator\n"]},{"metadata":{"id":"cHjk7R5bxR3Q","colab_type":"code","colab":{}},"cell_type":"code","source":["import cv2 # to load the images\n","import numpy as np # to do matrix mnupulations \n","from os.path import isfile, join # to manupulate file paths\n","from os import listdir # get list of all the files in a directory\n","from random import shuffle # shuffle the data (file paths)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xklVoVK9Lw08","colab_type":"code","colab":{}},"cell_type":"code","source":["class DataSetGenerator:\n","    def __init__(self, data_dir):\n","        self.data_dir = data_dir\n","        self.data_labels = self.get_data_labels()\n","        self.data_info = self.get_data_paths()\n","\n","    def get_data_labels(self):\n","        data_labels = []\n","        for filename in listdir(self.data_dir):\n","            if not isfile(join(self.data_dir, filename)):\n","                data_labels.append(filename)\n","        return data_labels\n","\n","    def get_data_paths(self):\n","        data_paths = []\n","        for label in self.data_labels:\n","            img_lists=[]\n","            path = join(self.data_dir, label)\n","            for filename in listdir(path):\n","                tokens = filename.split('.')\n","                if tokens[-1] == 'jpg':\n","                    image_path=join(path, filename)\n","                    img_lists.append(image_path)\n","            shuffle(img_lists)\n","            data_paths.append(img_lists)\n","        return data_paths\n","\n","      \n","# Now the data_path list should contain two lists one with all the \n","# lists of image paths for dog and one with list of all the image \n","# paths for cat      \n","\n","\n","# So we got all the image file paths and the corresponding labels, \n","# Now what? How to get the images?, We will be using the Python’s \n","# concept of generator, and the concept of yield to create the \n","# mini-batches on the fly and delete them after we are done training \n","# our network on it.      \n","\n","    def get_mini_batches(self, batch_size=10, image_size=(200, 200), allchannel=True):\n","        images = []\n","        labels = []\n","        empty=False\n","        \n","        # counter for the current iteration for each class.\n","        counter=0\n","        \n","        # each_batch = int(10 / 2) = 5\n","        # batch_size for each class\n","        each_batch_size=int(batch_size/len(self.data_info))\n","        \n","        # we will break this loop when none of the classes have \n","        # any images left to train\n","        while True:\n","            \n","            # inner for loop to get images from each and every class one by one\n","            for i in range(len(self.data_labels)):\n","                label = np.zeros(len(self.data_labels),dtype=int)\n","                label[i] = 1\n","                \n","                \n","                # So before loading any images, we have to check if that\n","                # class has any image_path left in the list, so we checked \n","                # if the length of that list of that particular class is \n","                # less than our counter value. if it is then we considered \n","                # it as empty and continuing to the next class. if it’s not \n","                # we are setting the empty flag as False and loading the image \n","                # using cv2.imread() method.\n","\n","                if len(self.data_info[i]) < counter+1:\n","                    empty=True\n","                    continue\n","                empty=False\n","                img = cv2.imread(self.data_info[i][counter])\n","                img = self.resizeAndPad(img, image_size)\n","                if not allchannel:\n","                    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","                    img = np.reshape(img, (img.shape[0], img.shape[1], 1))\n","                images.append(img)\n","                labels.append(label)\n","            \n","            # counter for the current iteration for each class.\n","            counter+=1\n","\n","            if empty:\n","                break\n","            # if the iterator is multiple of batch size return the mini batch\n","            if (counter)%each_batch_size == 0:\n","                yield np.array(images,dtype=np.uint8), np.array(labels,dtype=np.uint8)\n","                del images\n","                del labels\n","                images=[]\n","                labels=[]\n","                \n","# So here first we checked if we are shrinking the image or enlarging. \n","# Cuz the cv2.INTER_AREA method is better for shrinking the image where as  \n","# cv2.INTER_CUBIC  is better for enlarging the image.\n","\n","# Next, we are checking if it’s a horizontal image or a vertical image. \n","# and padding the image with zeros so that it becomes a square image.\n","\n","# Then we applied the cv2.resize  method to scale the image \n","# according to the given size.\n","                \n","                \n","    def resizeAndPad(self, img, size):\n","        h, w = img.shape[:2]\n","\n","        sh, sw = size\n","        # interpolation method\n","        if h > sh or w > sw:  # shrinking image\n","            interp = cv2.INTER_AREA\n","        else: # stretching image\n","            interp = cv2.INTER_CUBIC\n","\n","        # aspect ratio of image\n","        aspect = w/h\n","\n","        # padding\n","        if aspect > 1: # horizontal image\n","            new_shape = list(img.shape)\n","            new_shape[0] = w\n","            new_shape[1] = w\n","            new_shape = tuple(new_shape)\n","            new_img=np.zeros(new_shape, dtype=np.uint8)\n","            h_offset=int((w-h)/2)\n","            new_img[h_offset:h_offset+h, :, :] = img.copy()\n","\n","        elif aspect < 1: # vertical image\n","            new_shape = list(img.shape)\n","            new_shape[0] = h\n","            new_shape[1] = h\n","            new_shape = tuple(new_shape)\n","            new_img = np.zeros(new_shape,dtype=np.uint8)\n","            w_offset = int((h-w) / 2)\n","            new_img[:, w_offset:w_offset + w, :] = img.copy()\n","        else:\n","            new_img = img.copy()\n","        # scale and pad\n","        scaled_img = cv2.resize(new_img, size, interpolation=interp)\n","        return scaled_img\n","                "],"execution_count":0,"outputs":[]},{"metadata":{"id":"cMy0rtwozvnA","colab_type":"text"},"cell_type":"markdown","source":["# Image classifier"]},{"metadata":{"id":"1YbpXCAzzyue","colab_type":"code","colab":{}},"cell_type":"code","source":["ls"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ga12I5KAz6Sz","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow as tf \n","\n","class NetworkBuilder: \n","    def __init__(self): \n","        pass\n","      \n","    #=========================Convolution Layer=========================#\n","    \n","    # feature_size is the size of the kernel\n","    # input_layer is to attach a new layer in the model\n","    # strides  [batch step, height step, width step, channel step]\n","    def attach_conv_layer(self, input_layer, output_size=32, feature_size=(5, 5), strides=[1, 1, 1, 1], padding='SAME', summary=False):\n","        with tf.name_scope(\"Convolution\") as scope:\n","            \n","            # To create the new conv layer we first need the size of the input \n","            # image. or more specifically the number of the channel the input \n","            # image has. So, to get the size of the last axis, \n","            # use input_layer.get_shape().as_list()[-1] \n","            input_size = input_layer.get_shape().as_list()[-1]\n","          \n","            # weights for conv layer should be in this shape [kernal height, \n","            # kernel weight, input channel size, output channels ].\n","            weights = tf.Variable(tf.random_normal([feature_size[0], feature_size[1], input_size, output_size]), name='conv_weights')\n","            \n","            if summary:\n","                tf.summary.histogram(weights.name, weights)\n","            \n","            biases = tf.Variable(tf.random_normal([output_size]),name='conv_biases')\n","            \n","            # TensorFlow’s convolutional conv2d operation expects a 4-dimensional \n","            # tensor with dimensions corresponding to batch, width, height and channel.\n","\n","            conv = tf.nn.conv2d(input_layer, weights, strides=strides, padding=padding)+biases\n","            return conv\n","    \n","    #=========================The Pooling Layer=========================#\n","                                                                                \n","    # The ksize is the pooling size which should be in this format \n","    # [batch, height, width, channel]. We don’t want to merge any pixels \n","    # from batch and channel axis. So for default, we put 1 in those positions\n","    # and 2 in both height and width position. \n","    \n","    \n","    def attach_pooling_layer(self, input_layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME'):\n","        with tf.name_scope(\"Pooling\") as scope:\n","            return tf.nn.max_pool(input_layer, ksize=ksize, strides=strides, padding=padding)\n","\n","    #=========================Activation Layer=========================#\n","    \n","    def attach_relu_layer(self, input_layer):\n","        with tf.name_scope(\"Activation\") as scope:\n","            return tf.nn.relu(input_layer)\n","\n","    def attach_sigmoid_layer(self, input_layer):\n","        with tf.name_scope(\"Activation\") as scope:\n","            return tf.nn.sigmoid(input_layer)\n","\n","    def attach_softmax_layer(self, input_layer):\n","        with tf.name_scope(\"Activation\") as scope:\n","            return tf.nn.softmax(input_layer)\n","          \n","    #=========================Flatten Layer=========================#\n","    \n","    # Till now we were working with images, or feature maps which are also an \n","    # image in some form, and all are 3D in shape excluding the batch axis but \n","    # the fully connected layer only works with 1D so we have to convert that \n","    # 3d input to flat 1D input.\n","    \n","    def flatten(self, input_layer):\n","        with tf.name_scope(\"Flatten\") as scope:\n","            input_size = input_layer.get_shape().as_list()\n","            \n","            # calculated the total number of neurons (representing each \n","            # pixel values) in the input layer excluding the batch axis.\n","            new_size = input_size[-1] * input_size[-2] * input_size[-3]\n","            \n","            # size of the 1D vector for our fully connected layer. \n","            # So now we reshape the input layer to [batchsize, newsize] \n","            # where -1 is for batch size which means it can take any value\n","            return tf.reshape(input_layer, [-1, new_size])\n","  \n","  #=========================Dense Layer=========================#\n","    \n","          \n","    def attach_dense_layer(self, input_layer, size, summary=False):\n","        with tf.name_scope(\"Dense\") as scope:\n","            input_size = input_layer.get_shape().as_list()[-1]\n","            weights = tf.Variable(tf.random_normal([input_size, size]), name='dense_weigh')\n","            if summary:\n","                tf.summary.histogram(weights.name, weights)\n","            biases = tf.Variable(tf.random_normal([size]), name='dense_biases')\n","            dense = tf.matmul(input_layer, weights) + biases\n","            return dense\n","          \n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TjPA3HbEi2SI","colab_type":"text"},"cell_type":"markdown","source":["**About tf.reshape**\n","\n","[link text](https://www.tensorflow.org/api_docs/python/tf/reshape)\n","\n","If one component of shape is the special value -1, the size of that dimension is computed so that the total size remains constant. In particular, a shape of [-1] flattens into 1-D. **At most one component of shape can be -1.**\n","\n","\n","\n","```\n","# tensor 't' has shape [3, 2, 3]\n","# pass '[-1]' to flatten 't'\n","reshape(t, [-1]) ==> [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6]\n","---\n","\n","[1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6]\n","\n","# -1 can also be used to infer the shape\n","\n","# -1 is inferred to be 9:\n","reshape(t, [2, -1]) ==> [[1, 1, 1, 2, 2, 2, 3, 3, 3],\n","                         [4, 4, 4, 5, 5, 5, 6, 6, 6]]\n","                         \n","```\n"]},{"metadata":{"id":"6gg4kgEERD7z","colab_type":"text"},"cell_type":"markdown","source":["# Tensorboard setup"]},{"metadata":{"id":"00YLKXTDRFJ6","colab_type":"code","colab":{}},"cell_type":"code","source":["!mkdir tensorboard_tut"],"execution_count":0,"outputs":[]},{"metadata":{"id":"H-_N6qPIRJ07","colab_type":"code","colab":{}},"cell_type":"code","source":["cd tensorboard_tut"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Cqkx_Vh48Nlg","colab_type":"code","colab":{}},"cell_type":"code","source":["!mkdir summary_log"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Owy3wQOnRvrV","colab_type":"code","colab":{}},"cell_type":"code","source":["ls "],"execution_count":0,"outputs":[]},{"metadata":{"id":"B7dbYgeoSQH-","colab_type":"code","colab":{}},"cell_type":"code","source":["pwd"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zjEeAtRY_Gsj","colab_type":"text"},"cell_type":"markdown","source":["### Tensorboard Installation"]},{"metadata":{"id":"_aprsJ8aHWK6","colab_type":"code","colab":{}},"cell_type":"code","source":["LOG_DIR = \"/content/dataset_cat_dog/tensorboard_tut/summary_log/\"\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ifnhca-aHYID","colab_type":"code","colab":{}},"cell_type":"code","source":["\"\"\"Make sure we're able to connect to the TensorBoard service.\"\"\"\n","! curl http://localhost:6006"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SxGYwfu-Hd5z","colab_type":"code","colab":{}},"cell_type":"code","source":["\"\"\"## 2\n","Download and unzip [ngrok](https://ngrok.com).\n","\"\"\"\n","! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip > /dev/null 2>&1\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sRFpoT4zHnmp","colab_type":"code","colab":{}},"cell_type":"code","source":["! unzip ngrok-stable-linux-amd64.zip > /dev/null 2>&1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gSkkT-yuIf6D","colab_type":"code","colab":{}},"cell_type":"code","source":["! ls"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Bzb0PAso_Fy6","colab_type":"code","colab":{}},"cell_type":"code","source":["get_ipython().system_raw('./ngrok http 6006 &')\n","\n","! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_iaPyRwwHjNi","colab_type":"code","colab":{}},"cell_type":"code","source":["# Install\n","! npm install -g localtunnel\n","\n","# Tunnel port 6006 (TensorBoard assumed running)\n","get_ipython().system_raw('lt --port 6006 >> url.txt 2>&1 &')\n","\n","# Get url\n","!cat url.txt"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1E1Zd8Dj_bwr","colab_type":"text"},"cell_type":"markdown","source":["### Link to Tensorboard"]},{"metadata":{"id":"f6nQc80tMgUN","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow as tf\n","a = tf.constant(2)\n","b = tf.constant(3)\n","\n","x = tf.add(3,5)\n","\n","#using with clause \n","\n","with tf.Session() as sess:\n","  writer = tf.summary.FileWriter(\"/content/dataset_cat_dog/tensorboard_tut/summary_log/\", sess.graph)\n","  print (\"value of x : \",sess.run(x))\n","  \n","writer.close()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Zz1DSN0pIV8i","colab_type":"code","colab":{}},"cell_type":"code","source":["pwd"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UJVRaCb4I3PS","colab_type":"code","colab":{}},"cell_type":"code","source":["ls"],"execution_count":0,"outputs":[]},{"metadata":{"id":"w-_Vi2v78CSl","colab_type":"code","colab":{}},"cell_type":"code","source":["ls /content/dataset_cat_dog/tensorboard_tut/summary_log/ "],"execution_count":0,"outputs":[]},{"metadata":{"id":"k3SgKGbM_jDL","colab_type":"code","colab":{}},"cell_type":"code","source":["! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"E0JRz4-Ij1o6","colab_type":"text"},"cell_type":"markdown","source":["# Let’s Create a CNN Model in Tensorflow"]},{"metadata":{"id":"_ld3CK72jUH3","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow as tf\n","import datetime \n","import numpy as np \n","import os"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7zA6wbyLkHxJ","colab_type":"text"},"cell_type":"markdown","source":[" let’s create the place holders"]},{"metadata":{"id":"Z8CJgi7DkIGY","colab_type":"code","colab":{}},"cell_type":"code","source":["with tf.name_scope(\"Input\") as scope:\n","    input_img = tf.placeholder(dtype='float', shape=[None, 128, 128, 3], name=\"input\")\n","\n","with tf.name_scope(\"Target\") as scope:\n","    target_labels = tf.placeholder(dtype='float', shape=[None, 2], name=\"Targets\")\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0nYi5_uGkVLD","colab_type":"text"},"cell_type":"markdown","source":["Let’s Design the Model"]},{"metadata":{"id":"rvOykECLkKKP","colab_type":"code","colab":{}},"cell_type":"code","source":["nb = NetworkBuilder()\n","\n","with tf.name_scope(\"ModelV2\") as scope:\n","    model = input_img\n","    model = nb.attach_conv_layer(model, 32, summary=True)\n","    model = nb.attach_relu_layer(model)\n","    model = nb.attach_conv_layer(model, 32, summary=True)\n","    model = nb.attach_relu_layer(model)\n","    model = nb.attach_pooling_layer(model)\n","\n","    model = nb.attach_conv_layer(model, 64, summary=True)\n","    model = nb.attach_relu_layer(model)\n","    model = nb.attach_conv_layer(model, 64, summary=True)\n","    model = nb.attach_relu_layer(model)\n","    model = nb.attach_pooling_layer(model)\n","\n","    model = nb.attach_conv_layer(model, 128, summary=True)\n","    model = nb.attach_relu_layer(model)\n","    model = nb.attach_conv_layer(model, 128, summary=True)\n","    model = nb.attach_relu_layer(model)\n","    model = nb.attach_pooling_layer(model)\n","\n","    model = nb.flatten(model)\n","    model = nb.attach_dense_layer(model, 200, summary=True)\n","    model = nb.attach_sigmoid_layer(model)\n","    model = nb.attach_dense_layer(model, 32, summary=True)\n","    model = nb.attach_sigmoid_layer(model)\n","    model = nb.attach_dense_layer(model, 2)\n","    prediction = nb.attach_softmax_layer(model)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0FroS_3IlUBy","colab_type":"text"},"cell_type":"markdown","source":["**Now we will create the optimization and accuracy blocks\n","**"]},{"metadata":{"id":"HrW15jCSkZ9P","colab_type":"code","colab":{}},"cell_type":"code","source":["with tf.name_scope(\"Optimization\") as scope:\n","    global_step = tf.Variable(0, name='global_step', trainable=False)\n","    cost = tf.nn.softmax_cross_entropy_with_logits(logits=model, labels=target_labels)\n","    cost = tf.reduce_mean(cost)\n","    tf.summary.scalar(\"cost\", cost)\n","\n","    optimizer = tf.train.AdamOptimizer().minimize(cost,global_step=global_step)\n","\n","with tf.name_scope('accuracy') as scope:\n","    correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(target_labels, 1))\n","    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JKZBgsd9ldaG","colab_type":"text"},"cell_type":"markdown","source":["# let’s train it\n"]},{"metadata":{"id":"uEHMXmpSG0eh","colab_type":"code","colab":{}},"cell_type":"code","source":["pwd"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eEzjQerbHMLY","colab_type":"code","colab":{}},"cell_type":"code","source":["ls /content/dataset_cat_dog/tensorboard_tut/summary_log/"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NXptPHMADsTD","colab_type":"code","colab":{}},"cell_type":"code","source":["# we need to run this only once\n","#seperateData(\"./train\")\n","\n","dg = DataSetGenerator(\"/content/dataset_cat_dog/train\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yRqnsnjolYDl","colab_type":"code","colab":{}},"cell_type":"code","source":["epochs = 10\n","batchSize = 10\n","\n","saver = tf.train.Saver()\n","model_save_path=\"/content/dataset_cat_dog/saved model v2/\"\n","model_name='model'\n","\n","with tf.Session() as sess:\n","    summaryMerged = tf.summary.merge_all()\n","\n","    filename = \"/content/dataset_cat_dog/tensorboard_tut/summary_log/run\" + datetime.datetime.now().strftime(\"%Y-%m-%d--%H-%M-%s\")\n","    tf.global_variables_initializer().run()\n","\n","    if os.path.exists(model_save_path+'checkpoint'):\n","        saver = tf.train.import_meta_graph('./saved '+modelName+'/model.ckpt.meta')\n","        saver.restore(sess, tf.train.latest_checkpoint(model_save_path))\n","    writer = tf.summary.FileWriter(filename, sess.graph)\n","\n","    for epoch in range(epochs):\n","        batches = dg.get_mini_batches(batchSize,(128,128), allchannel=True)\n","        for imgs ,labels in batches:\n","            imgs=np.divide(imgs, 255)\n","            error, sumOut, acu, steps,_ = sess.run([cost, summaryMerged, accuracy,global_step,optimizer],\n","                                            feed_dict={input_img: imgs, target_labels: labels})\n","            writer.add_summary(sumOut, steps)\n","            print(\"epoch=\", epoch, \"Total Samples Trained=\", steps*batchSize, \"err=\", error, \"accuracy=\", acu)\n","            if steps % 100 == 0:\n","                print(\"Saving the model\")\n","                saver.save(sess, model_save_path+model_name, global_step=steps)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YKhGL-Hlli6C","colab_type":"code","colab":{}},"cell_type":"code","source":["batches = dg.get_mini_batches(batchSize,(128,128), allchannel=True)\n","imgs ,labels = batches"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZJQ5GhOGnvVJ","colab_type":"code","colab":{}},"cell_type":"code","source":["imgs.shape"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IqaFuel5JASp","colab_type":"code","colab":{}},"cell_type":"code","source":["ls"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uUEn1JYTAaSY","colab_type":"text"},"cell_type":"markdown","source":["# testing"]},{"metadata":{"id":"jovjOB4DAC5R","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}